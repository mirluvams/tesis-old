{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e8e071a-25df-4ffb-a742-2fb6277f6328",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 0.0. Instalar e importar bibliotecas y librerías necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73134b4f-cbca-4c0f-aefa-e4e3fd9608df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch  # Librería para operaciones de aprendizaje profundo\n",
    "import torch.nn as nn  # Módulo para construcción de redes neuronales\n",
    "import numpy as np  # Librería para operaciones numéricas eficientes\n",
    "import pandas as pd  # Librería para manipulación y análisis de datos\n",
    "import requests  # Librería para realizar solicitudes HTTP\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from PIL import Image, ImageFile  # Módulo para manipulación de imágenes\n",
    "\n",
    "from datasets import Dataset\n",
    "from datasets import ClassLabel as dsLabel\n",
    "from datasets import Image as dsImage\n",
    "from evaluate import load as load_metric  # Función para cargar métricas de evaluación\n",
    "import torchvision.transforms as transforms  # Transformaciones de imágenes\n",
    "from pathlib import Path  # Manejo de rutas de archivos y directorios\n",
    "\n",
    "from transformers import AutoFeatureExtractor, SwinForImageClassification  # Modelos de transformadores\n",
    "from transformers import AutoModelForImageClassification, TrainingArguments, Trainer  # Entrenamiento de modelos de imágenes\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True  # Cargar imágenes ligeramente corruptas\n",
    "\n",
    "import cv2 #modificar imágenes a escala de gris y redimensionar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a6502a-099e-4c5a-890f-75c4b6533f13",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 1.0. Preprocesamiento de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e494e6a2-b8fc-4df4-8bcb-15d7ded59f22",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1.1. Cargar datos\n",
    "\n",
    "**Descripción del conjunto de datos (dataset):**\n",
    "\n",
    "**Nombre del dataset:** NN_INPUT.feather\n",
    "\n",
    "**Estructura:**\n",
    "\n",
    "(4) columnas: \n",
    "* Path: nombre de la ruta de la imagen\n",
    "* FUM (marca 0.0 si no es, 1.0 sí es fumalora)\n",
    "* EXP (marca 0.0 si no es, 1.0 sí es explosión)\n",
    "* INAC (marca 0.0 si no es, 1.0 sí es inactivo)\n",
    "\n",
    "(21,931) filas:\n",
    "* Cada fila es el nombre de la ruta de una imagen que se encuentra almacenanda en el sistema de archivos con el mismo nombre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6f3dc5c-5329-470a-b52d-de4eb7f30b08",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Path</th>\n",
       "      <th>FUM</th>\n",
       "      <th>EXP</th>\n",
       "      <th>INAC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000/abr/p0423001.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000/abr/p0423002.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000/abr/p0423003.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000/abr/p0424001.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000/abr/p0424002.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21926</th>\n",
       "      <td>2023/mar/p0316234.jpeg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21927</th>\n",
       "      <td>2023/mar/p0317231.jpeg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21928</th>\n",
       "      <td>2023/mar/p0317232.jpeg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21929</th>\n",
       "      <td>2023/mar/p0317233.jpeg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21930</th>\n",
       "      <td>2023/mar/p0317234.jpeg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21931 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Path  FUM  EXP  INAC\n",
       "0       2000/abr/p0423001.jpg  0.0  0.0   1.0\n",
       "1       2000/abr/p0423002.jpg  1.0  0.0   0.0\n",
       "2       2000/abr/p0423003.jpg  1.0  0.0   0.0\n",
       "3       2000/abr/p0424001.jpg  1.0  0.0   0.0\n",
       "4       2000/abr/p0424002.jpg  1.0  0.0   0.0\n",
       "...                       ...  ...  ...   ...\n",
       "21926  2023/mar/p0316234.jpeg  1.0  0.0   0.0\n",
       "21927  2023/mar/p0317231.jpeg  1.0  1.0   0.0\n",
       "21928  2023/mar/p0317232.jpeg  1.0  1.0   0.0\n",
       "21929  2023/mar/p0317233.jpeg  1.0  1.0   0.0\n",
       "21930  2023/mar/p0317234.jpeg  1.0  1.0   0.0\n",
       "\n",
       "[21931 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definidiendo mi dataset (almacenando el archivo NN_INPUT.feather en data)\n",
    "data = pd.read_feather(\"NN_INPUT.feather\");\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e435777d-b40f-4112-9c78-fc85d3cd539f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1.2. Limpiar datos\n",
    "\n",
    "* Revisar el tamaño del dataset\n",
    "* Revisar si hay valores NAN, null\n",
    "* Desechar filas inexistentes -> Hay filas que no tienen un Path que no hace match con las imágenes guardadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "516cb231-0340-493a-96a2-23bcef900eb1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Revisar la cantidad de imágenes\n",
    "#data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "796447f9-5c44-446e-9d0a-6eac3c8237af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Revisar si hay valores NAN, null\n",
    "#data.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0a2b6f1-f571-497d-86c7-490249e3f434",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ba98832-b12e-4222-858e-96d373e185e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Obtén el directorio actual\n",
    "current_directory = os.getcwd()\n",
    "images_folder = 'images'\n",
    "\n",
    "# Imprime información sobre las rutas y su existencia\n",
    "for i, r in data.iterrows():\n",
    "    full_path = os.path.join(current_directory, images_folder, r[\"Path\"])\n",
    "    #print(f\"Index: {i}, Path: {full_path}, Exists: {Path(full_path).exists()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c65fb6dd-436b-42a6-b48e-221a44ab71af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directorio actual: C:\\Users\\alexi\\OneDrive\\ENES\\MiriTesis\n"
     ]
    }
   ],
   "source": [
    "# directorio actual\n",
    "current_directory = os.getcwd()\n",
    "print(f\"Directorio actual: {current_directory}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "267c0145-6436-41a7-92b4-20e306b6ac0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\alexi\\\\OneDrive\\\\ENES\\\\MiriTesis\\\\images\\\\2023/mar/p0317234.jpeg'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#full_path = os.path.join(current_directory, r[\"Path\"])\n",
    "full_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7239b5c-6e8c-4bf2-be49-bf600d6a785c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desechar las filas inexistentes\n",
    "drop = []\n",
    "for i, r in data.iterrows():\n",
    "    full_path = os.path.join(current_directory, images_folder, r[\"Path\"])\n",
    "    if not Path(full_path).exists():\n",
    "        drop.append(i)\n",
    "    #print(i,r,full_path,Path(full_path).exists())\n",
    "    \n",
    "data.drop(drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20db348c-514a-43b6-ac11-8748ad17599d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Path</th>\n",
       "      <th>FUM</th>\n",
       "      <th>EXP</th>\n",
       "      <th>INAC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000/abr/p0423001.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000/abr/p0423002.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000/abr/p0423003.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000/abr/p0424001.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000/abr/p0424002.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21926</th>\n",
       "      <td>2023/mar/p0316234.jpeg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21927</th>\n",
       "      <td>2023/mar/p0317231.jpeg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21928</th>\n",
       "      <td>2023/mar/p0317232.jpeg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21929</th>\n",
       "      <td>2023/mar/p0317233.jpeg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21930</th>\n",
       "      <td>2023/mar/p0317234.jpeg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21931 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Path  FUM  EXP  INAC\n",
       "0       2000/abr/p0423001.jpg  0.0  0.0   1.0\n",
       "1       2000/abr/p0423002.jpg  1.0  0.0   0.0\n",
       "2       2000/abr/p0423003.jpg  1.0  0.0   0.0\n",
       "3       2000/abr/p0424001.jpg  1.0  0.0   0.0\n",
       "4       2000/abr/p0424002.jpg  1.0  0.0   0.0\n",
       "...                       ...  ...  ...   ...\n",
       "21926  2023/mar/p0316234.jpeg  1.0  0.0   0.0\n",
       "21927  2023/mar/p0317231.jpeg  1.0  1.0   0.0\n",
       "21928  2023/mar/p0317232.jpeg  1.0  1.0   0.0\n",
       "21929  2023/mar/p0317233.jpeg  1.0  1.0   0.0\n",
       "21930  2023/mar/p0317234.jpeg  1.0  1.0   0.0\n",
       "\n",
       "[21931 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f3af36b-1c25-44bd-948a-abdeab0213ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se eliminaron 0 filas inexistentes.\n"
     ]
    }
   ],
   "source": [
    "# Revisar cuántas filas (nombres de ruta) inexistentes se eliminaron\n",
    "print(f\"Se eliminaron {len(drop)} filas inexistentes.\")\n",
    "\n",
    "# ¿QUÉEEEE?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fced9e73-230b-4f16-9cbb-1919c136098a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\alexi\\\\OneDrive\\\\ENES\\\\MiriTesis'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f32eb4-0419-4421-ae3c-8145c46edaf4",
   "metadata": {},
   "source": [
    "## 1.3. Modificación de imágenes con OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d51044a7-3f88-42cd-8b44-14a2d5535388",
   "metadata": {},
   "outputs": [],
   "source": [
    "def procesar_imagen(ruta):\n",
    "    # Carga la imagen a color\n",
    "    full_path = os.path.join(current_directory, images_folder, ruta)\n",
    "    if not os.path.exists(full_path):\n",
    "        print(f\"{ruta} no existe!\")\n",
    "        return None\n",
    "        \n",
    "    imagen_gris = cv2.imread(full_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    # Verifica si la imagen se cargó correctamente\n",
    "    if imagen_gris is None:\n",
    "        print(f\"Error al cargar la imagen en la ruta: {ruta}\")\n",
    "        return None\n",
    "\n",
    "    # Convierte la imagen a escala de grises\n",
    "    #imagen_gris = cv2.cvtColor(imagen_color, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Cambia el tamaño de la imagen\n",
    "    nuevo_tamano = (340, 240)  # factor de escala .5 de las imágenes originales\n",
    "    imagen_redimensionada = cv2.resize(imagen_gris, nuevo_tamano)\n",
    "\n",
    "    return np.asarray(imagen_redimensionada)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f4c2b349-dc95-409c-8365-f5b0371fccbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error al cargar la imagen en la ruta: 2000/dic/p1201001.gif\n",
      "Error al cargar la imagen en la ruta: 2000/dic/p1203001.gif\n",
      "Error al cargar la imagen en la ruta: 2000/dic/p1215003.jpg\n",
      "Error al cargar la imagen en la ruta: 2000/dic/p1219008.jpg\n",
      "Error al cargar la imagen en la ruta: 2000/dic/p1224001.gif\n",
      "Error al cargar la imagen en la ruta: 2001/jul/p0703012.jpg\n",
      "Error al cargar la imagen en la ruta: 2002/ene/p0123024.jpg\n",
      "Error al cargar la imagen en la ruta: 2002/ene/p0123025.jpg\n",
      "Error al cargar la imagen en la ruta: 2013/may/p0512131.jpg\n",
      "Error al cargar la imagen en la ruta: 2014/oct/p1015146.gif\n",
      "Error al cargar la imagen en la ruta: 2014/nov/p1105147.gif\n",
      "Error al cargar la imagen en la ruta: 2014/nov/p1105147.gif\n",
      "Error al cargar la imagen en la ruta: 2015/feb/p0212153.gif\n",
      "Error al cargar la imagen en la ruta: 2015/feb/p0220152.gif\n",
      "Error al cargar la imagen en la ruta: 2015/feb/p0220155.gif\n",
      "Error al cargar la imagen en la ruta: 2015/feb/p0220155.gif\n",
      "Error al cargar la imagen en la ruta: 2015/feb/p0224159.gif\n",
      "Error al cargar la imagen en la ruta: 2015/feb/p02251521.gif\n",
      "Error al cargar la imagen en la ruta: 2015/mar/p0308151.gif\n",
      "Error al cargar la imagen en la ruta: 2015/mar/p0308157.gif\n",
      "Error al cargar la imagen en la ruta: 2015/abr/p0408156.gif\n",
      "Error al cargar la imagen en la ruta: 2015/jun/p0613154.gif\n",
      "Error al cargar la imagen en la ruta: 2016/ene/p0126166.gif\n",
      "Error al cargar la imagen en la ruta: 2016/ene/p0126167.gif\n",
      "Error al cargar la imagen en la ruta: 2016/ene/p0127161.gif\n",
      "Error al cargar la imagen en la ruta: 2016/jun/p0609164.gif\n",
      "Error al cargar la imagen en la ruta: 2016/jun/p0609165.gif\n",
      "Error al cargar la imagen en la ruta: 2016/jul/p0731166.gif\n",
      "Error al cargar la imagen en la ruta: 2016/ago/p0830162.gif\n",
      "Error al cargar la imagen en la ruta: 2016/ago/p0830163.gif\n",
      "Error al cargar la imagen en la ruta: 2017/jul/p0710171.gif\n",
      "Error al cargar la imagen en la ruta: 2018/abr/p0408184.gif\n",
      "Error al cargar la imagen en la ruta: 2018/abr/p0409185.gif\n",
      "Error al cargar la imagen en la ruta: 2019/may/p0522194.gif\n"
     ]
    }
   ],
   "source": [
    "# Aplica la función procesar_imagen a la columna 'Path' del DataFrame\n",
    "data['imagen_procesada'] = data['Path'].apply(procesar_imagen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ca7afb69-585e-4fbf-986c-5e7bf3fb869a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Path</th>\n",
       "      <th>FUM</th>\n",
       "      <th>EXP</th>\n",
       "      <th>INAC</th>\n",
       "      <th>imagen_procesada</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000/abr/p0423001.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[[119, 141, 138, 135, 138, 138, 137, 136, 135,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Path  FUM  EXP  INAC  \\\n",
       "0  2000/abr/p0423001.jpg  0.0  0.0   1.0   \n",
       "\n",
       "                                    imagen_procesada  \n",
       "0  [[119, 141, 138, 135, 138, 138, 137, 136, 135,...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a9985e-e5f5-4a96-8ee7-ab2cae60f48a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1.4. Transformación de datos\n",
    "* Compatibilidad con la API datasets\n",
    "* ```from_generator()``` te permite convertir los datos generados por un generador en un objeto de conjunto de datos que es compatible con todas las funcionalidades y utilidades de ```datasets.```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "77c80ca1-3257-42f2-b3bc-1ab381531418",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def GEN():\n",
    "    for idx,row in data.iterrows():\n",
    "        Image,FUM,EXP,INA,Proc = row\n",
    "        if(Proc is None):\n",
    "            continue\n",
    "        Proc=np.asarray(Proc)\n",
    "        Label=\"UNK\"\n",
    "        if FUM>0:\n",
    "            if EXP>0:\n",
    "                Label=\"EXP+FUM\"\n",
    "            else:\n",
    "                Label=\"FUM\"\n",
    "        elif EXP>0:\n",
    "            Label=\"EXP\"\n",
    "        elif INA>0:\n",
    "            Label=\"INA\"\n",
    "        yield {\n",
    "            \"image\":dsImage(Proc),\n",
    "            \"label\":Label\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8408adfd-7cb0-4261-b138-2bf93f86109e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54fac38710f848aa93ad780b96dcdc0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "PermissionError",
     "evalue": "[WinError 32] The process cannot access the file because it is being used by another process: 'C:/Users/alexi/.cache/huggingface/datasets/generator/default-b1208a348c895e7e/0.0.0.incomplete\\\\generator-train-00000-00000-of-NNNNN.arrow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mArrowInvalid\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32m~\\mambaforge\\lib\\site-packages\\datasets\\arrow_writer.py:189\u001b[0m, in \u001b[0;36mTypedSequence.__arrow_array__\u001b[1;34m(self, type)\u001b[0m\n\u001b[0;32m    188\u001b[0m     trying_cast_to_python_objects \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 189\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to_python_objects\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43monly_1d_for_numpy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    190\u001b[0m \u001b[38;5;66;03m# use smaller integer precisions if possible\u001b[39;00m\n",
      "File \u001b[1;32m~\\mambaforge\\lib\\site-packages\\pyarrow\\array.pxi:327\u001b[0m, in \u001b[0;36mpyarrow.lib.array\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\mambaforge\\lib\\site-packages\\pyarrow\\array.pxi:39\u001b[0m, in \u001b[0;36mpyarrow.lib._sequence_to_array\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\mambaforge\\lib\\site-packages\\pyarrow\\error.pxi:144\u001b[0m, in \u001b[0;36mpyarrow.lib.pyarrow_internal_check_status\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\mambaforge\\lib\\site-packages\\pyarrow\\error.pxi:100\u001b[0m, in \u001b[0;36mpyarrow.lib.check_status\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mArrowInvalid\u001b[0m: Could not convert Image(decode=array([[119, 141, 138, ..., 104, 105, 105],\n       [120, 140, 138, ..., 105, 105, 106],\n       [121, 137, 138, ..., 103, 104, 105],\n       ...,\n       [ 68,  86,  84, ...,  49,  47,  46],\n       [ 71,  84,  81, ...,  48,  47,  46],\n       [ 82, 101, 101, ...,   0,   1,   1]], dtype=uint8), id=None) with type Image: did not recognize Python value type when inferring an Arrow data type",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mArrowInvalid\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32m~\\mambaforge\\lib\\site-packages\\datasets\\builder.py:1694\u001b[0m, in \u001b[0;36mGeneratorBasedBuilder._prepare_split_single\u001b[1;34m(self, gen_kwargs, fpath, file_format, max_shard_size, split_info, check_duplicate_keys, job_id)\u001b[0m\n\u001b[0;32m   1693\u001b[0m example \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mfeatures\u001b[38;5;241m.\u001b[39mencode_example(record) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mfeatures \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m record\n\u001b[1;32m-> 1694\u001b[0m \u001b[43mwriter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1695\u001b[0m num_examples_progress_update \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32m~\\mambaforge\\lib\\site-packages\\datasets\\arrow_writer.py:490\u001b[0m, in \u001b[0;36mArrowWriter.write\u001b[1;34m(self, example, key, writer_batch_size)\u001b[0m\n\u001b[0;32m    488\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhkey_record \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 490\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_examples_on_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\mambaforge\\lib\\site-packages\\datasets\\arrow_writer.py:448\u001b[0m, in \u001b[0;36mArrowWriter.write_examples_on_file\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    444\u001b[0m         batch_examples[col] \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    445\u001b[0m             row[\u001b[38;5;241m0\u001b[39m][col]\u001b[38;5;241m.\u001b[39mto_pylist()[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(row[\u001b[38;5;241m0\u001b[39m][col], (pa\u001b[38;5;241m.\u001b[39mArray, pa\u001b[38;5;241m.\u001b[39mChunkedArray)) \u001b[38;5;28;01melse\u001b[39;00m row[\u001b[38;5;241m0\u001b[39m][col]\n\u001b[0;32m    446\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_examples\n\u001b[0;32m    447\u001b[0m         ]\n\u001b[1;32m--> 448\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_examples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_examples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_examples \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32m~\\mambaforge\\lib\\site-packages\\datasets\\arrow_writer.py:555\u001b[0m, in \u001b[0;36mArrowWriter.write_batch\u001b[1;34m(self, batch_examples, writer_batch_size)\u001b[0m\n\u001b[0;32m    554\u001b[0m typed_sequence \u001b[38;5;241m=\u001b[39m OptimizedTypedSequence(col_values, \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39mcol_type, try_type\u001b[38;5;241m=\u001b[39mcol_try_type, col\u001b[38;5;241m=\u001b[39mcol)\n\u001b[1;32m--> 555\u001b[0m arrays\u001b[38;5;241m.\u001b[39mappend(\u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtyped_sequence\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    556\u001b[0m inferred_features[col] \u001b[38;5;241m=\u001b[39m typed_sequence\u001b[38;5;241m.\u001b[39mget_inferred_type()\n",
      "File \u001b[1;32m~\\mambaforge\\lib\\site-packages\\pyarrow\\array.pxi:243\u001b[0m, in \u001b[0;36mpyarrow.lib.array\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\mambaforge\\lib\\site-packages\\pyarrow\\array.pxi:110\u001b[0m, in \u001b[0;36mpyarrow.lib._handle_arrow_array_protocol\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\mambaforge\\lib\\site-packages\\datasets\\arrow_writer.py:253\u001b[0m, in \u001b[0;36mTypedSequence.__arrow_array__\u001b[1;34m(self, type)\u001b[0m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m trying_cast_to_python_objects \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not convert\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e):\n\u001b[1;32m--> 253\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to_python_objects\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43monly_1d_for_numpy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimize_list_casting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    254\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\mambaforge\\lib\\site-packages\\pyarrow\\array.pxi:327\u001b[0m, in \u001b[0;36mpyarrow.lib.array\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\mambaforge\\lib\\site-packages\\pyarrow\\array.pxi:39\u001b[0m, in \u001b[0;36mpyarrow.lib._sequence_to_array\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\mambaforge\\lib\\site-packages\\pyarrow\\error.pxi:144\u001b[0m, in \u001b[0;36mpyarrow.lib.pyarrow_internal_check_status\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\mambaforge\\lib\\site-packages\\pyarrow\\error.pxi:100\u001b[0m, in \u001b[0;36mpyarrow.lib.check_status\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mArrowInvalid\u001b[0m: Could not convert Image(decode=array([[119, 141, 138, ..., 104, 105, 105],\n       [120, 140, 138, ..., 105, 105, 106],\n       [121, 137, 138, ..., 103, 104, 105],\n       ...,\n       [ 68,  86,  84, ...,  49,  47,  46],\n       [ 71,  84,  81, ...,  48,  47,  46],\n       [ 82, 101, 101, ...,   0,   1,   1]], dtype=uint8), id=None) with type Image: did not recognize Python value type when inferring an Arrow data type",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mArrowInvalid\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32m~\\mambaforge\\lib\\site-packages\\datasets\\arrow_writer.py:189\u001b[0m, in \u001b[0;36mTypedSequence.__arrow_array__\u001b[1;34m(self, type)\u001b[0m\n\u001b[0;32m    188\u001b[0m     trying_cast_to_python_objects \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 189\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to_python_objects\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43monly_1d_for_numpy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    190\u001b[0m \u001b[38;5;66;03m# use smaller integer precisions if possible\u001b[39;00m\n",
      "File \u001b[1;32m~\\mambaforge\\lib\\site-packages\\pyarrow\\array.pxi:327\u001b[0m, in \u001b[0;36mpyarrow.lib.array\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\mambaforge\\lib\\site-packages\\pyarrow\\array.pxi:39\u001b[0m, in \u001b[0;36mpyarrow.lib._sequence_to_array\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\mambaforge\\lib\\site-packages\\pyarrow\\error.pxi:144\u001b[0m, in \u001b[0;36mpyarrow.lib.pyarrow_internal_check_status\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\mambaforge\\lib\\site-packages\\pyarrow\\error.pxi:100\u001b[0m, in \u001b[0;36mpyarrow.lib.check_status\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mArrowInvalid\u001b[0m: Could not convert Image(decode=array([[119, 141, 138, ..., 104, 105, 105],\n       [120, 140, 138, ..., 105, 105, 106],\n       [121, 137, 138, ..., 103, 104, 105],\n       ...,\n       [ 68,  86,  84, ...,  49,  47,  46],\n       [ 71,  84,  81, ...,  48,  47,  46],\n       [ 82, 101, 101, ...,   0,   1,   1]], dtype=uint8), id=None) with type Image: did not recognize Python value type when inferring an Arrow data type",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mArrowInvalid\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32m~\\mambaforge\\lib\\site-packages\\datasets\\builder.py:1703\u001b[0m, in \u001b[0;36mGeneratorBasedBuilder._prepare_split_single\u001b[1;34m(self, gen_kwargs, fpath, file_format, max_shard_size, split_info, check_duplicate_keys, job_id)\u001b[0m\n\u001b[0;32m   1702\u001b[0m num_shards \u001b[38;5;241m=\u001b[39m shard_id \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1703\u001b[0m num_examples, num_bytes \u001b[38;5;241m=\u001b[39m \u001b[43mwriter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfinalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1704\u001b[0m writer\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32m~\\mambaforge\\lib\\site-packages\\datasets\\arrow_writer.py:586\u001b[0m, in \u001b[0;36mArrowWriter.finalize\u001b[1;34m(self, close_stream)\u001b[0m\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhkey_record \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 586\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_examples_on_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    587\u001b[0m \u001b[38;5;66;03m# If schema is known, infer features even if no examples were written\u001b[39;00m\n",
      "File \u001b[1;32m~\\mambaforge\\lib\\site-packages\\datasets\\arrow_writer.py:448\u001b[0m, in \u001b[0;36mArrowWriter.write_examples_on_file\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    444\u001b[0m         batch_examples[col] \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    445\u001b[0m             row[\u001b[38;5;241m0\u001b[39m][col]\u001b[38;5;241m.\u001b[39mto_pylist()[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(row[\u001b[38;5;241m0\u001b[39m][col], (pa\u001b[38;5;241m.\u001b[39mArray, pa\u001b[38;5;241m.\u001b[39mChunkedArray)) \u001b[38;5;28;01melse\u001b[39;00m row[\u001b[38;5;241m0\u001b[39m][col]\n\u001b[0;32m    446\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_examples\n\u001b[0;32m    447\u001b[0m         ]\n\u001b[1;32m--> 448\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_examples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_examples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_examples \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32m~\\mambaforge\\lib\\site-packages\\datasets\\arrow_writer.py:555\u001b[0m, in \u001b[0;36mArrowWriter.write_batch\u001b[1;34m(self, batch_examples, writer_batch_size)\u001b[0m\n\u001b[0;32m    554\u001b[0m typed_sequence \u001b[38;5;241m=\u001b[39m OptimizedTypedSequence(col_values, \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39mcol_type, try_type\u001b[38;5;241m=\u001b[39mcol_try_type, col\u001b[38;5;241m=\u001b[39mcol)\n\u001b[1;32m--> 555\u001b[0m arrays\u001b[38;5;241m.\u001b[39mappend(\u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtyped_sequence\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    556\u001b[0m inferred_features[col] \u001b[38;5;241m=\u001b[39m typed_sequence\u001b[38;5;241m.\u001b[39mget_inferred_type()\n",
      "File \u001b[1;32m~\\mambaforge\\lib\\site-packages\\pyarrow\\array.pxi:243\u001b[0m, in \u001b[0;36mpyarrow.lib.array\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\mambaforge\\lib\\site-packages\\pyarrow\\array.pxi:110\u001b[0m, in \u001b[0;36mpyarrow.lib._handle_arrow_array_protocol\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\mambaforge\\lib\\site-packages\\datasets\\arrow_writer.py:253\u001b[0m, in \u001b[0;36mTypedSequence.__arrow_array__\u001b[1;34m(self, type)\u001b[0m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m trying_cast_to_python_objects \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not convert\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e):\n\u001b[1;32m--> 253\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to_python_objects\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43monly_1d_for_numpy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimize_list_casting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    254\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\mambaforge\\lib\\site-packages\\pyarrow\\array.pxi:327\u001b[0m, in \u001b[0;36mpyarrow.lib.array\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\mambaforge\\lib\\site-packages\\pyarrow\\array.pxi:39\u001b[0m, in \u001b[0;36mpyarrow.lib._sequence_to_array\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\mambaforge\\lib\\site-packages\\pyarrow\\error.pxi:144\u001b[0m, in \u001b[0;36mpyarrow.lib.pyarrow_internal_check_status\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\mambaforge\\lib\\site-packages\\pyarrow\\error.pxi:100\u001b[0m, in \u001b[0;36mpyarrow.lib.check_status\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mArrowInvalid\u001b[0m: Could not convert Image(decode=array([[119, 141, 138, ..., 104, 105, 105],\n       [120, 140, 138, ..., 105, 105, 106],\n       [121, 137, 138, ..., 103, 104, 105],\n       ...,\n       [ 68,  86,  84, ...,  49,  47,  46],\n       [ 71,  84,  81, ...,  48,  47,  46],\n       [ 82, 101, 101, ...,   0,   1,   1]], dtype=uint8), id=None) with type Image: did not recognize Python value type when inferring an Arrow data type",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mDatasetGenerationError\u001b[0m                    Traceback (most recent call last)",
      "File \u001b[1;32m~\\mambaforge\\lib\\site-packages\\datasets\\builder.py:908\u001b[0m, in \u001b[0;36mDatasetBuilder.download_and_prepare.<locals>.incomplete_dir\u001b[1;34m(dirname)\u001b[0m\n\u001b[0;32m    907\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 908\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m tmp_dir\n\u001b[0;32m    909\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(dirname):\n",
      "File \u001b[1;32m~\\mambaforge\\lib\\site-packages\\datasets\\builder.py:954\u001b[0m, in \u001b[0;36mDatasetBuilder.download_and_prepare\u001b[1;34m(self, output_dir, download_config, download_mode, verification_mode, ignore_verifications, try_from_hf_gcs, dl_manager, base_path, use_auth_token, file_format, max_shard_size, num_proc, storage_options, **download_and_prepare_kwargs)\u001b[0m\n\u001b[0;32m    953\u001b[0m         prepare_split_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_proc\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m num_proc\n\u001b[1;32m--> 954\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_download_and_prepare(\n\u001b[0;32m    955\u001b[0m         dl_manager\u001b[38;5;241m=\u001b[39mdl_manager,\n\u001b[0;32m    956\u001b[0m         verification_mode\u001b[38;5;241m=\u001b[39mverification_mode,\n\u001b[0;32m    957\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mprepare_split_kwargs,\n\u001b[0;32m    958\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdownload_and_prepare_kwargs,\n\u001b[0;32m    959\u001b[0m     )\n\u001b[0;32m    960\u001b[0m \u001b[38;5;66;03m# Sync info\u001b[39;00m\n",
      "File \u001b[1;32m~\\mambaforge\\lib\\site-packages\\datasets\\builder.py:1717\u001b[0m, in \u001b[0;36mGeneratorBasedBuilder._download_and_prepare\u001b[1;34m(self, dl_manager, verification_mode, **prepare_splits_kwargs)\u001b[0m\n\u001b[0;32m   1716\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_download_and_prepare\u001b[39m(\u001b[38;5;28mself\u001b[39m, dl_manager, verification_mode, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mprepare_splits_kwargs):\n\u001b[1;32m-> 1717\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m_download_and_prepare(\n\u001b[0;32m   1718\u001b[0m         dl_manager,\n\u001b[0;32m   1719\u001b[0m         verification_mode,\n\u001b[0;32m   1720\u001b[0m         check_duplicate_keys\u001b[38;5;241m=\u001b[39mverification_mode \u001b[38;5;241m==\u001b[39m VerificationMode\u001b[38;5;241m.\u001b[39mBASIC_CHECKS\n\u001b[0;32m   1721\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m verification_mode \u001b[38;5;241m==\u001b[39m VerificationMode\u001b[38;5;241m.\u001b[39mALL_CHECKS,\n\u001b[0;32m   1722\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mprepare_splits_kwargs,\n\u001b[0;32m   1723\u001b[0m     )\n",
      "File \u001b[1;32m~\\mambaforge\\lib\\site-packages\\datasets\\builder.py:1049\u001b[0m, in \u001b[0;36mDatasetBuilder._download_and_prepare\u001b[1;34m(self, dl_manager, verification_mode, **prepare_split_kwargs)\u001b[0m\n\u001b[0;32m   1047\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1048\u001b[0m     \u001b[38;5;66;03m# Prepare split will record examples associated to the split\u001b[39;00m\n\u001b[1;32m-> 1049\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_split(split_generator, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mprepare_split_kwargs)\n\u001b[0;32m   1050\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\mambaforge\\lib\\site-packages\\datasets\\builder.py:1555\u001b[0m, in \u001b[0;36mGeneratorBasedBuilder._prepare_split\u001b[1;34m(self, split_generator, check_duplicate_keys, file_format, num_proc, max_shard_size)\u001b[0m\n\u001b[0;32m   1554\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pbar:\n\u001b[1;32m-> 1555\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m job_id, done, content \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_split_single(\n\u001b[0;32m   1556\u001b[0m         gen_kwargs\u001b[38;5;241m=\u001b[39mgen_kwargs, job_id\u001b[38;5;241m=\u001b[39mjob_id, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_prepare_split_args\n\u001b[0;32m   1557\u001b[0m     ):\n\u001b[0;32m   1558\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m done:\n",
      "File \u001b[1;32m~\\mambaforge\\lib\\site-packages\\datasets\\builder.py:1712\u001b[0m, in \u001b[0;36mGeneratorBasedBuilder._prepare_split_single\u001b[1;34m(self, gen_kwargs, fpath, file_format, max_shard_size, split_info, check_duplicate_keys, job_id)\u001b[0m\n\u001b[0;32m   1711\u001b[0m         e \u001b[38;5;241m=\u001b[39m e\u001b[38;5;241m.\u001b[39m__context__\n\u001b[1;32m-> 1712\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DatasetGenerationError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while generating the dataset\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m   1714\u001b[0m \u001b[38;5;28;01myield\u001b[39;00m job_id, \u001b[38;5;28;01mTrue\u001b[39;00m, (total_num_examples, total_num_bytes, writer\u001b[38;5;241m.\u001b[39m_features, num_shards, shard_lengths)\n",
      "\u001b[1;31mDatasetGenerationError\u001b[0m: An error occurred while generating the dataset",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Crear y darle formato a un conjunto de datos a partir de la función generadora GEN()\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Importante porque queremos trababajar con 'datasets' de HuggingFace después.\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m Data\u001b[38;5;241m=\u001b[39m\u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mGEN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;66;03m#.cast_column(\"image\",dsImage())#.cast_column(\"label\",dsLabel(names=[\"UNK\",\"EXP\",\"FUM\",\"EXP+FUM\",\"INA\"]))\u001b[39;00m\n\u001b[0;32m      5\u001b[0m Data\n",
      "File \u001b[1;32m~\\mambaforge\\lib\\site-packages\\datasets\\arrow_dataset.py:1072\u001b[0m, in \u001b[0;36mDataset.from_generator\u001b[1;34m(generator, features, cache_dir, keep_in_memory, gen_kwargs, num_proc, **kwargs)\u001b[0m\n\u001b[0;32m   1016\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Create a Dataset from a generator.\u001b[39;00m\n\u001b[0;32m   1017\u001b[0m \n\u001b[0;32m   1018\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1060\u001b[0m \u001b[38;5;124;03m```\u001b[39;00m\n\u001b[0;32m   1061\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1062\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgenerator\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GeneratorDatasetInputStream\n\u001b[0;32m   1064\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mGeneratorDatasetInputStream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1065\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1066\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1067\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1068\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeep_in_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1069\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgen_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgen_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1070\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_proc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_proc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1071\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m-> 1072\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\mambaforge\\lib\\site-packages\\datasets\\io\\generator.py:47\u001b[0m, in \u001b[0;36mGeneratorDatasetInputStream.read\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     44\u001b[0m     verification_mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     45\u001b[0m     base_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m---> 47\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_and_prepare\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverification_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverification_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# try_from_hf_gcs=try_from_hf_gcs,\u001b[39;49;00m\n\u001b[0;32m     52\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbase_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_proc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_proc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilder\u001b[38;5;241m.\u001b[39mas_dataset(\n\u001b[0;32m     56\u001b[0m         split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m, verification_mode\u001b[38;5;241m=\u001b[39mverification_mode, in_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeep_in_memory\n\u001b[0;32m     57\u001b[0m     )\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dataset\n",
      "File \u001b[1;32m~\\mambaforge\\lib\\site-packages\\datasets\\builder.py:934\u001b[0m, in \u001b[0;36mDatasetBuilder.download_and_prepare\u001b[1;34m(self, output_dir, download_config, download_mode, verification_mode, ignore_verifications, try_from_hf_gcs, dl_manager, base_path, use_auth_token, file_format, max_shard_size, num_proc, storage_options, **download_and_prepare_kwargs)\u001b[0m\n\u001b[0;32m    931\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_manual_download(dl_manager)\n\u001b[0;32m    933\u001b[0m \u001b[38;5;66;03m# Create a tmp dir and rename to self._output_dir on successful exit.\u001b[39;00m\n\u001b[1;32m--> 934\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m incomplete_dir(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_dir) \u001b[38;5;28;01mas\u001b[39;00m tmp_output_dir:\n\u001b[0;32m    935\u001b[0m     \u001b[38;5;66;03m# Temporarily assign _output_dir to tmp_data_dir to avoid having to forward\u001b[39;00m\n\u001b[0;32m    936\u001b[0m     \u001b[38;5;66;03m# it to every sub function.\u001b[39;00m\n\u001b[0;32m    937\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m temporary_assignment(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_output_dir\u001b[39m\u001b[38;5;124m\"\u001b[39m, tmp_output_dir):\n\u001b[0;32m    938\u001b[0m         \u001b[38;5;66;03m# Try to download the already prepared dataset files\u001b[39;00m\n\u001b[0;32m    939\u001b[0m         downloaded_from_gcs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\mambaforge\\lib\\contextlib.py:153\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[1;34m(self, typ, value, traceback)\u001b[0m\n\u001b[0;32m    151\u001b[0m     value \u001b[38;5;241m=\u001b[39m typ()\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 153\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraceback\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[0;32m    156\u001b[0m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m value\n",
      "File \u001b[1;32m~\\mambaforge\\lib\\site-packages\\datasets\\builder.py:915\u001b[0m, in \u001b[0;36mDatasetBuilder.download_and_prepare.<locals>.incomplete_dir\u001b[1;34m(dirname)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    914\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(tmp_dir):\n\u001b[1;32m--> 915\u001b[0m         \u001b[43mshutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrmtree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtmp_dir\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\mambaforge\\lib\\shutil.py:750\u001b[0m, in \u001b[0;36mrmtree\u001b[1;34m(path, ignore_errors, onerror)\u001b[0m\n\u001b[0;32m    748\u001b[0m     \u001b[38;5;66;03m# can't continue even if onerror hook returns\u001b[39;00m\n\u001b[0;32m    749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 750\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_rmtree_unsafe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43monerror\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\mambaforge\\lib\\shutil.py:620\u001b[0m, in \u001b[0;36m_rmtree_unsafe\u001b[1;34m(path, onerror)\u001b[0m\n\u001b[0;32m    618\u001b[0m             os\u001b[38;5;241m.\u001b[39munlink(fullname)\n\u001b[0;32m    619\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m--> 620\u001b[0m             \u001b[43monerror\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munlink\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfullname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    621\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    622\u001b[0m     os\u001b[38;5;241m.\u001b[39mrmdir(path)\n",
      "File \u001b[1;32m~\\mambaforge\\lib\\shutil.py:618\u001b[0m, in \u001b[0;36m_rmtree_unsafe\u001b[1;34m(path, onerror)\u001b[0m\n\u001b[0;32m    616\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    617\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 618\u001b[0m         \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munlink\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfullname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    619\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[0;32m    620\u001b[0m         onerror(os\u001b[38;5;241m.\u001b[39munlink, fullname, sys\u001b[38;5;241m.\u001b[39mexc_info())\n",
      "\u001b[1;31mPermissionError\u001b[0m: [WinError 32] The process cannot access the file because it is being used by another process: 'C:/Users/alexi/.cache/huggingface/datasets/generator/default-b1208a348c895e7e/0.0.0.incomplete\\\\generator-train-00000-00000-of-NNNNN.arrow'"
     ]
    }
   ],
   "source": [
    "# Crear y darle formato a un conjunto de datos a partir de la función generadora GEN()\n",
    "# Importante porque queremos trababajar con 'datasets' de HuggingFace después.\n",
    "\n",
    "Data=Dataset.from_generator(GEN, cache_dir=None)#.cast_column(\"image\",dsImage())#.cast_column(\"label\",dsLabel(names=[\"UNK\",\"EXP\",\"FUM\",\"EXP+FUM\",\"INA\"]))\n",
    "Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b696654b-58d2-47dd-9693-18b26d15d6f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(Data[0]['image'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30251755-6a3d-457b-9b47-e92bd7c1f76e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 2.0. Entrenamiento de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850a6058-6d7d-4676-846e-a76c03b9ad12",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2.1. Separar los datos en:\n",
    "    - entranamiento (train) -> 95%\n",
    "    - evaluación (test) -> 5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e0d83b-f819-4031-8eb8-8fa2b3f7a9d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Data=Data.train_test_split(.05)\n",
    "Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edca445f-83c7-42f1-b720-6f23beee40ad",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2.2. Preprocesamiento del dataset de entrenamiento\n",
    "* Representación de las etiquetas\n",
    "* Mapeo dibireccional entre etiquetas e identificadores numéricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f212710-3aea-497e-9a46-167d429f5c14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Etiquetas del dataset de entrenamiento\n",
    "labels = Data[\"train\"].features[\"label\"].names\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf3e255-b3ae-46da-b85f-6e523860cc7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Gracias a 'ClassLabel' se crea este mapeo para representar las etiquetas de manera numérica  \n",
    "label2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82441992-b46b-4031-adf3-3bb550623c73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Se puede hacer al inverso también\n",
    "id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbd48ef-f8e5-44d1-addc-98dcec7998dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Mapeo bidireccional entre nombres de etiquetas e identificadores numéricos\n",
    "\n",
    "label2id, id2label = dict(), dict()\n",
    "for i, label in enumerate(labels):\n",
    "    label2id[label] = i\n",
    "    id2label[i] = label\n",
    "    \n",
    "# Ejemplo: acceder al nombre de la etiqueta asociada con el identificador numérico 3 \n",
    "id2label[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0920591-be81-46f4-a241-7d3fe0d4050b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Visualizando imágenes y su etiqueta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53d9ba1-cb4f-47e8-9fc8-6604d967d5dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Muestra la imagen en el índice 134 en el dataset de entrenamiento (train)\n",
    "Data[\"train\"][134][\"image\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e4fff5-d390-4e54-a837-6af99a57eff9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Muestra la etiqueta en el índice 134 en el dataset de entrenamiento (train)\n",
    "\n",
    "print(Data[\"train\"][134][\"label\"])\n",
    "\n",
    "# Despliega las etiquetas y su identificador\n",
    "print(id2label)\n",
    "\n",
    "# ¡Es correcto, la imagen y la etiqueta hacen match! :D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4b44c3-b671-4df7-ae01-40791b2a169c",
   "metadata": {},
   "source": [
    "# 3.0. Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e47d932-b732-4aab-a2bf-17c86af25f36",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3.1. Elección de modelo\n",
    "* Cargar modelo\n",
    "* Cargar procesador de características para extraer y procesar las más revelantes utilizando la arq. del modelo 'swinv2'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1f6bbf-cd8f-40d6-9db3-d6ebb92f34c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cargando el modelo\n",
    "model_name=\"microsoft/swinv2-small-patch4-window16-256\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db65b652-6f40-49f1-aa7f-9247394fd9e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Se crea un procesador de características de imágenes utilizando el modelo preentrenado especificado por 'model_name' \n",
    "image_processor = AutoFeatureExtractor.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b3c13d-30c5-4231-b883-3b28b58de82c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3.2. Preprocesamiento de las imágenes para ser usadas en el modelo\n",
    "\n",
    "Mediante diferentes transformaciones se asegura que las imágenes de entrada estén en el formato y la escala adecuados antes de ser utilizadas para entrenar o evaluar el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c941096-7bfa-47dd-92dc-a574e3340f74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Importar transformaciones específicas de la biblioteca torchvision para el preprocesamiento de imágenes\n",
    "\n",
    "from torchvision.transforms import (\n",
    "    CenterCrop,\n",
    "    Compose,\n",
    "    Normalize,\n",
    "    RandomHorizontalFlip,\n",
    "    RandomResizedCrop,\n",
    "    Resize,\n",
    "    ToTensor,\n",
    ")\n",
    "\n",
    "# Crear una normalización para las imágenes utilizando las estadísticas de imagen del procesador de características\n",
    "normalize = Normalize(mean=image_processor.image_mean, std=image_processor.image_std)\n",
    "\n",
    "\n",
    "# Determinar el tamaño y tamaño de recorte de las imágenes según las especificaciones del procesador de imágenes\n",
    "if \"height\" in image_processor.size:\n",
    "    size = (image_processor.size[\"height\"], image_processor.size[\"width\"])\n",
    "    crop_size = size\n",
    "    max_size = None # No se establece un tamaño máximo\n",
    "elif \"shortest_edge\" in image_processor.size:\n",
    "    size = image_processor.size[\"shortest_edge\"]\n",
    "    crop_size = (size, size)\n",
    "    max_size = image_processor.size.get(\"longest_edge\")\n",
    "    \n",
    "else:\n",
    "    # Establecer valores predeterminados o manejar el error\n",
    "    size = (default_height, default_width)  # Valores predeterminados\n",
    "    crop_size = size\n",
    "    max_size = None\n",
    "\n",
    "# Definir transformaciones de preprocesamiento para el dataset de entrenamiento\n",
    "train_transforms = Compose(\n",
    "        [\n",
    "            RandomResizedCrop(crop_size),\n",
    "            RandomHorizontalFlip(),\n",
    "            ToTensor(),\n",
    "            normalize,\n",
    "        ]\n",
    "    )\n",
    "\n",
    "# Definir transformaciones de preprocesamiento para el dataset de validación\n",
    "val_transforms = Compose(\n",
    "        [\n",
    "            Resize(size),\n",
    "            CenterCrop(crop_size),\n",
    "            ToTensor(),\n",
    "            normalize,\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628af14d-8d0a-4123-8aca-187e5bda2613",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Preprocesar un batch de ejemplos de entrenamiento\n",
    "def preprocess_train(example_batch):\n",
    "\n",
    "    # Se aplica 'train_transforms' a cada imagen en el batch y se asigna el resultado a \"pixel_values\"\n",
    "    example_batch[\"pixel_values\"] = [\n",
    "        train_transforms(image.convert(\"RGB\")) for image in example_batch[\"image\"]\n",
    "    ]\n",
    "    return example_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c84271-74c8-43ff-9c19-fd3d1b6f0548",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Preprocesar un batch de ejemplos de validación\n",
    "def preprocess_val(example_batch):\n",
    "    \n",
    "    # Se aplica 'val_transforms' a cada imagen en el batch y se asigna el resultado a \"pixel_values\"\n",
    "    example_batch[\"pixel_values\"] = [val_transforms(image.convert(\"RGB\")) for image in example_batch[\"image\"]]\n",
    "    return example_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd178e62-3f50-4508-b915-876ef4ff2511",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Se asigna el conjunto de datos de entrenamiento del objeto 'Data' a la variable 'train_ds'\n",
    "train_ds = Data['train']\n",
    "\n",
    "# Se asigna el conjunto de datos de prueba del objeto 'Data' a la variable 'val_ds'\n",
    "val_ds = Data['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbac2f7d-a47d-4b07-8d86-a469520709ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Se configuran las transformaciones predefinidas 'preprocess_train' y 'preprocess_val' en los conjuntos de datos de entrenamiento y prueba\n",
    "\n",
    "train_ds.set_transform(preprocess_train)\n",
    "val_ds.set_transform(preprocess_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a1f02b-bfcf-4dc0-b4ac-1fd07240e279",
   "metadata": {},
   "source": [
    "Aplicar las transformaciones predefinidas a los conjuntos de datos, asegura que las imágenes se procesen de manera consistente y adecuada antes de ser utilizadas en las etapas de entrenamiento y evaluación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66374f03-f45b-45e1-8b90-c1da6364dee9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Visualizando cómo luce el dataset de entrenamiento\n",
    "train_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecca3b9d-81fe-4743-ad60-9959dd094dda",
   "metadata": {},
   "source": [
    "## 3.3. Creación del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134f794e-b1ec-4d68-beb8-fbf0b75b4245",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Crear un modelo para la clasificación de imágenes utilizando el modelo preentrenado especificado\n",
    "model = AutoModelForImageClassification.from_pretrained(\n",
    "    model_name, \n",
    "    label2id=label2id,\n",
    "    id2label=id2label,\n",
    "    ignore_mismatched_sizes = True, # se proporciona esto en caso de que estés planeando hacer fine-tune a un checkpoint que ya está fine-tuned\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069b9222-9dcb-4d76-acdc-d5bafb38204e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cargar métrica de \"accuracy\"\n",
    "metric = load_metric(\"accuracy\")\n",
    "\n",
    "# Cargar otras-diferentes métricas\n",
    "\n",
    "precision_metric = load_metric(\"precision\")\n",
    "recall_metric = load_metric(\"recall\")\n",
    "f1_metric = load_metric(\"f1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0caad226-0424-4aa1-9a82-664daad0615c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extraer el nombre del modelo a partir de la ruta y crear argumentos de entrenamiento\n",
    "model_name_b = model_name.split(\"/\")[-1]  # Extraer el nombre del modelo de la ruta\n",
    "\n",
    "# Configurar los argumentos de entrenamiento\n",
    "args = TrainingArguments(\n",
    "    f\"{model_name_b}-finetuned-popocatepetl\",  # Nombre del directorio para el modelo fine-tuned\n",
    "    remove_unused_columns=False,\n",
    "    evaluation_strategy=\"epoch\",  # Evaluar después de cada época\n",
    "    save_strategy=\"epoch\",  # Guardar después de cada época\n",
    "    learning_rate=5e-5,\n",
    "    fp16=True,  # Utilizar precisión de 16 bits\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=10,  # Número de épocas de entrenamiento\n",
    "    warmup_ratio=0.1,  # Proporción de pasos de calentamiento\n",
    "    logging_steps=10,  # Intervalo para registrar información\n",
    "    load_best_model_at_end=True,  # Cargar el mejor modelo al final del entrenamiento\n",
    "    metric_for_best_model=\"accuracy\",  # Utilizar la métrica de \"accuracy\" para el mejor modelo\n",
    "    push_to_hub=False,  # No subir a Hugging Face Model Hub\n",
    "    report_to=[],  # No informar a ningún servicio\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ea1f6a-75a6-4e17-9e97-d0d2cd3f914c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    \"\"\"Calcula la precisión en un batch de predicciones\"\"\"\n",
    "    \n",
    "    # Calcula las predicciones utilizando el índice de la clase con mayor probabilidad\n",
    "    predictions = np.argmax(eval_pred.predictions, axis=1)\n",
    "    \n",
    "    # Calcula la métrica (en este caso, la métrica definida previamente) utilizando las predicciones y las etiquetas reales\n",
    "    return metric.compute(predictions=predictions, references=eval_pred.label_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903cf558-d3dd-4be2-9b75-9b95294696c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def collate_fn(examples):\n",
    "    \"\"\"Función de agrupación utilizada durante la creación de batch de ejemplos\"\"\"\n",
    "    \n",
    "    # Apila los valores de píxeles de todas las imágenes en el lote\n",
    "    pixel_values = torch.stack([example[\"pixel_values\"] for example in examples])\n",
    "    \n",
    "    # Crea un tensor con las etiquetas correspondientes a cada ejemplo en el lote\n",
    "    labels = torch.tensor([example[\"label\"] for example in examples])\n",
    "    \n",
    "    # Retorna un diccionario que contiene los valores de píxeles y las etiquetas agrupados\n",
    "    return {\"pixel_values\": pixel_values, \"labels\": labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56752fe6-7109-4ecb-972f-6c2ac2020e4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_ds[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468326fd-2f25-444f-8652-bdd881610f0e",
   "metadata": {},
   "source": [
    "Primer ejemplo en el conjunto de datos train_ds. \n",
    "\n",
    "train_ds contiene ejemplos de imágenes y sus etiquetas correspondientes.\n",
    "\n",
    "train_ds[0]: primer ejemplo en este conjunto de datos, que generalmente incluye la imagen y su etiqueta. \n",
    "Un diccionario con claves \"image\", \"label\", \"pixel_values\", que te proporcionan la imagen y la etiqueta y los pixeles de la imagen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89b51d2-c3d2-4534-b434-87a0ee91eb75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Crear un objeto Trainer para la fase de entrenamiento y evaluación del modelo\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,  # Modelo a entrenar y evaluar\n",
    "    args,  # Argumentos de entrenamiento configurados previamente\n",
    "    train_dataset=train_ds,  # Conjunto de datos de entrenamiento\n",
    "    eval_dataset=val_ds,  # Conjunto de datos de validación/evaluación\n",
    "    tokenizer=image_processor,  # Procesador de imágenes para tokenizar\n",
    "    compute_metrics=compute_metrics,  # Función para calcular métricas de evaluación\n",
    "    data_collator=collate_fn,  # Función para agrupar ejemplos en batches\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66022730-ee7e-4b15-9916-7828dc917ef2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Iniciar el proceso de entrenamiento utilizando el objeto Trainer\n",
    "\n",
    "train_results = trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6020d4b-f6b1-4984-9926-c88aebb87349",
   "metadata": {},
   "source": [
    "Se inicia el proceso de entrenamiento del modelo utilizando el objeto trainer que se creó previamente.\n",
    "* ```train_results``` almacenará los resultados del proceso de entrenamiento (información sobre la pérdida, tiempo de entrenamiento, tasa de aprendizaje, etc)\n",
    "*```train()``` del objeto ```trainer``` llevará a cabo el entrenamiento del modelo utilizando los datos del conjunto de entrenamiento ```(train_ds)``` según la configuración de los argumentos ```(args)```.  Durante el proceso, el modelo ajustará sus pesos y aprenderá a partir de los ejemplos de entrenamiento. Al final del entrenamiento, los resultados se almacenarán en la variable ```train_results```, y se podrá usar esta información para evaluar cómo el modelo ha mejorado a lo largo del proceso de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f5f5b7-6e02-4953-a16e-683db0289594",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Guardar el modelo entrenado y registrar métricas y estado del entrenamiento\n",
    "\n",
    "trainer.save_model()  # Guardar el modelo entrenado\n",
    "trainer.log_metrics(\"train\", train_results.metrics)  # Registrar métricas de entrenamiento\n",
    "trainer.save_metrics(\"train\", train_results.metrics)  # Guardar métricas de entrenamiento\n",
    "trainer.save_state()  # Guardar el estado del entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469c41cc-973f-4663-9bac-ff8354f7801e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extraer el nombre base del modelo preentrenado\n",
    "model_name_b = model_name.split(\"/\")[-1]\n",
    "\n",
    "# Cargar el modelo finetuned a partir del nombre base y configuraciones\n",
    "model = AutoModelForImageClassification.from_pretrained(\n",
    "    f\"{model_name_b}-finetuned-popocatepetl\",  # Cargar el modelo finetuned\n",
    "    label2id=label2id,  # Configuración de mapeo de etiquetas a IDs\n",
    "    id2label=id2label,  # Configuración de mapeo de IDs a etiquetas\n",
    "    ignore_mismatched_sizes=True,  # Ignorar tamaños incompatibles (si es necesario)\n",
    ").to(\"cuda\")  # Mover el modelo a la GPU (si está disponible)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43cc88ea-a728-496d-9ba0-a2fadd047415",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Suprimir la notación científica -> imprimir números en coma flotante\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7124e98b-a72c-4dea-be23-181f48a9fe0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar un índice aleatorio del conjunto de prueba\n",
    "idx = np.random.choice(len(Data[\"test\"]))\n",
    "\n",
    "# Obtener la fila correspondiente al índice seleccionado\n",
    "row = Data[\"test\"][idx]\n",
    "\n",
    "# Procesar la imagen de entrada y obtener las predicciones del modelo\n",
    "inputs = image_processor(images=row[\"image\"], return_tensors=\"pt\")[\"pixel_values\"].to(\"cuda\")\n",
    "outputs = model(pixel_values=inputs)\n",
    "logits = outputs.logits\n",
    "\n",
    "# Imprimir las logits y las probabilidades\n",
    "print(\"LOGITS:\", logits)\n",
    "\n",
    "# Calcular las probabilidades ~suavizadas~\n",
    "probabilities = nn.functional.softmax(logits, dim=-1)\n",
    "probabilities = probabilities.detach().cpu().numpy().flatten()\n",
    "print(\"LOGITS CON SUAVITEL:\", probabilities)\n",
    "print(\"LA SUMA\", probabilities.sum())\n",
    "\n",
    "# Imprimir el mapeo de etiquetas a IDs\n",
    "print(model.config.label2id)\n",
    "\n",
    "# Obtener el índice de la clase predicha\n",
    "predicted_class_idx = logits.argmax(-1).item()\n",
    "\n",
    "# Imprimir la clase predicha y la clase real\n",
    "print(\"Predicted class:\", model.config.id2label[predicted_class_idx])\n",
    "print(\"Real class:\", model.config.id2label[row[\"label\"]])\n",
    "\n",
    "# Imprimir las probabilidades en porcentaje\n",
    "print(probabilities * 100)\n",
    "\n",
    "# Devolver la imagen original\n",
    "row[\"image\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d0d7bf-31a3-4363-9891-a59932410ad0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Establecer un estilo para la gráfica\n",
    "plt.style.use('seaborn')\n",
    "\n",
    "# Crear una figura para el gráfico de barras\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Etiquetas en el eje x\n",
    "display_labels = [\"INA\", \"FUM\", \"EXP\", \"EXP+FUM\", \"UNK\"]\n",
    "\n",
    "# Crear el gráfico de barras\n",
    "bars = plt.bar(display_labels, [probabilities[model.config.label2id[x]] * 100 for x in display_labels], color='dodgerblue', edgecolor='black', linewidth=1.5, alpha=0.8)\n",
    "\n",
    "# Agregar etiquetas con las probabilidades en las barras\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, yval + 2, round(yval, 2), ha='center', va='bottom', fontsize=10, color='black')\n",
    "\n",
    "# Etiquetas para los ejes y título del gráfico\n",
    "plt.xlabel(\"Etiqueta\", fontsize=12)\n",
    "plt.ylabel(\"Probabilidad (%)\", fontsize=12)\n",
    "plt.title(\"Probabilidades de etiqueta\", fontsize=14)\n",
    "\n",
    "# Ajustar los márgenes y mostrar el gráfico\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4500f62-7352-43e8-b4fb-10fd2d6696f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
